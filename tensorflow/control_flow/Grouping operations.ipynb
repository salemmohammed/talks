{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering parameters from one set of variables to another\n",
    "\n",
    "Example: Deep Q-Network, need to send \"online\" parameters to the \"target\" parameters periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper to create dummy graph with many value to be transferred from one Variable to another.\n",
    "def create_var_updates_and_init():\n",
    "    tf.reset_default_graph()\n",
    "    print('Creating variables...')\n",
    "    # Create dummy lists of variables for example\n",
    "    master_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    replica_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    # Create assign ops for each variable\n",
    "    update_ops = []\n",
    "    for i, var in enumerate(replica_vars):\n",
    "        master_var = master_vars[i]\n",
    "        update_ops.append(var.assign(master_var))\n",
    "    # initalization operation\n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Done.')\n",
    "    return update_ops, init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we run all of the `assign` ops?\n",
    "\n",
    "I've seen things like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Time elapsed: 0.5819320678710938 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Run each update in a separate Session.run() call\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    for update in update_ops:\n",
    "        sess.run(update)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Time elapsed: 0.014588594436645508 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "with tf.control_dependencies(update_ops):\n",
    "    assign_all = tf.no_op()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax can be made even cleaner by using the `tf.group` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Time elapsed: 0.015064001083374023 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "assign_all = tf.group(*update_ops)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a grouping operation is cleaner, faster, more idiomatic. Compared to the `tf.control_dependencies()` version above, `tf.group()` provides some additional functionality under-the-hood, making sure that operations are grouped according to their device. [Check out the implementation here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2784-L2846)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.tuple`\n",
    "\n",
    "If you want to synchronize multiple parallel operations, [`tf.tuple()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/tuple) is an easy solution. You simply pass in a list of tensors, and `tf.tuple()` prevents future operations from using those tensors until they have all been computed.\n",
    "\n",
    "_Note: TensorFlow operations automatically wait for all dependencies to finish before executing. Use `tf.tuple` for situations where you need to explicitly provide synchronization._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_matmul(dims):\n",
    "    return tf.matmul(tf.random_normal([dims, dims]), tf.random_normal([dims, dims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_a = make_matmul(100)\n",
    "tensor_b = make_matmul(1000)\n",
    "tensor_c = make_matmul(10000)\n",
    "sync_a, sync_b, sync_c = tf.tuple([tensor_a, tensor_b, tensor_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
