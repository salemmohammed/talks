{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "copyright": "Copyright 2017 Sam Abrahams. All Rights Reserved."
   },
   "source": [
    "_Copyright 2017 Sam Abrahams. All Rights Reserved._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_tensorboard_graph(path):\n",
    "    \"\"\"Helper to export graph data to be explored in `tensorboard`\"\"\"\n",
    "    tb_dir = os.path.join('tbout', path)\n",
    "    print('Exporting TensorBoard graph to {}'.format(tb_dir))\n",
    "    tf.summary.FileWriter(tb_dir, graph=tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control dependencies\n",
    "\n",
    "### Race conditions: a contrived (but demonstrative) example\n",
    "\n",
    "In the below code, notice that both `a` and `b` try to set the value of the `Variable`, `var`. Because there is no implicit dependency between `a` and `b`, they can run in either order each time a `Session` runs them. This causes unstable results, as illustrated with output printed to console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Our mutable state\n",
    "var = tf.Variable(0)\n",
    "a = tf.assign(var, 2 * var)\n",
    "b = tf.assign_add(var, 2)\n",
    "c = a + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Print the value of c over multiple iterations to show non-determinism\n",
    "for _ in range(5):\n",
    "    with tf.Session() as sess:\n",
    "        vals = []\n",
    "        sess.run(init)\n",
    "        for _ in range(10):\n",
    "            val = sess.run(c)\n",
    "            vals.append(val)\n",
    "        print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is no implicit dependency, we can force an _explicit_ dependency by using [`tf.control_dependencies()`](https://www.tensorflow.org/api_docs/python/tf/control_dependencies). Below, we use it to add `a` as a dependency to `b`, forcing `b` to wait until `a` has finished before running. Because of this, our execution order, and thus our output, is now completely deterministic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Our mutable state\n",
    "var = tf.Variable(0)\n",
    "a = tf.assign(var, 2 * var)\n",
    "# Force b to wait for a\n",
    "with tf.control_dependencies([a]):\n",
    "    b = tf.assign_add(var, 2)\n",
    "c = a + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Each run will now be identical\n",
    "for _ in range(5):\n",
    "    with tf.Session() as sess:\n",
    "        vals = []\n",
    "        sess.run(init)\n",
    "        for _ in range(10):\n",
    "            val = sess.run(c)\n",
    "            vals.append(val)\n",
    "        print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering parameters from one set of variables to another\n",
    "\n",
    "Example: Deep Q-Network, need to send \"online\" parameters to the \"target\" parameters periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper to create dummy graph with many value to be transferred from one Variable to another.\n",
    "def create_var_updates_and_init():\n",
    "    tf.reset_default_graph()\n",
    "    print('Creating variables...')\n",
    "    # Create dummy lists of variables for example\n",
    "    master_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    replica_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    # Create assign ops for each variable\n",
    "    update_ops = []\n",
    "    for i, var in enumerate(replica_vars):\n",
    "        master_var = master_vars[i]\n",
    "        update_ops.append(var.assign(master_var))\n",
    "    # initalization operation\n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Done.')\n",
    "    return update_ops, init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we run all of the `assign` ops? I've seen things like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Run each update in a separate Session.run() call\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    print('Updating Variables...')\n",
    "    for update in update_ops:\n",
    "        sess.run(update)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "with tf.control_dependencies(update_ops):\n",
    "    assign_all = tf.no_op()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Updating Variables...')\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.group`\n",
    "\n",
    "The syntax can be made cleaner by using the `tf.group` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "assign_all = tf.group(*update_ops)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a grouping operation is cleaner, faster, more idiomatic. Compared to the `tf.control_dependencies()` version above, `tf.group()` provides some additional functionality under-the-hood, making sure that operations are grouped according to their device. [Check out the implementation here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2784-L2846)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.tuple`\n",
    "\n",
    "If you want to synchronize multiple parallel operations, [`tf.tuple()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/tuple) is an easy solution. You simply pass in a list of tensors, and `tf.tuple()` prevents future operations from using those tensors until they have all been computed.\n",
    "\n",
    "_Note: TensorFlow operations automatically wait for all dependencies to finish before executing. Use `tf.tuple` for situations where you need to explicitly provide synchronization._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_matmul(dims):\n",
    "    return tf.matmul(tf.random_normal([dims, dims]), tf.random_normal([dims, dims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_a = make_matmul(100)\n",
    "tensor_b = make_matmul(1000)\n",
    "tensor_c = make_matmul(10000)\n",
    "sync_a, sync_b, sync_c = tf.tuple([tensor_a, tensor_b, tensor_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.cond`\n",
    "\n",
    "`tf.cond` is basically an `if/else` statement. You provide a boolean predicate and two functions which return tensors. One will run if the predicate is `True`, the other if it is `False`. Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "pred = tf.placeholder(tf.bool)\n",
    "def run_if_true():\n",
    "    return tf.add(3, 3)\n",
    "def run_if_false():\n",
    "    return tf.square(3)\n",
    "out = tf.cond(pred, run_if_true, run_if_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can run this multiple times and see the result from randomly selecting a true/false input\n",
    "with tf.Session() as sess:\n",
    "    choice = np.random.choice([True, False])\n",
    "    feed_dict = {pred: choice}\n",
    "    res = sess.run(out, feed_dict)\n",
    "    print('Choice: {}\\tResult: {}'.format(choice, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple functions, we can use lambdas instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "pred = tf.placeholder(tf.bool)\n",
    "out = tf.cond(pred, lambda: tf.add(3, 3), lambda: tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic `tf.case` example\n",
    "\n",
    "Try adjusting the `feed_dict` value for `prev` to see how the graph execution changes depending on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "prev = tf.placeholder(tf.float32)\n",
    "a = (prev < 0,  lambda: prev + 3)\n",
    "b = (prev < 10, lambda: prev * 3)\n",
    "c = (prev < 20, lambda: prev - 3)\n",
    "default = lambda: prev / 3\n",
    "pairs = [a, b, c]\n",
    "out = tf.case(pairs, default)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(out, {prev: 21})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Depth\n",
    "\n",
    "https://arxiv.org/abs/1603.09382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_depth_conv2d(inputs, filters, kernel_size, keep_prob, padding='same', activation=tf.nn.relu, name=None):\n",
    "    default_name = tf.get_default_graph().unique_name('stochastic_depth_conv')\n",
    "    with tf.variable_scope(name, default_name):\n",
    "        def full_layer():\n",
    "            return tf.layers.conv2d(inputs, filters, kernel_size, padding=padding, activation=activation, name='conv')\n",
    "        def skip_layer():\n",
    "            if inputs.get_shape().as_list()[-1] != filters:\n",
    "                return tf.layers.conv2d(inputs, filters, [1, 1], padding=padding, activation=activation, name='skip')\n",
    "            else:\n",
    "                return inputs\n",
    "        pred = tf.random_uniform([]) < keep_prob\n",
    "        return tf.cond(pred, full_layer, skip_layer), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv, _ = stochastic_depth_conv2d(inputs, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[32, 228, 228, 3]),\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)\n",
    "\n",
    "export_tensorboard_graph('stochastic_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing with TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=tbout/stochastic_depth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking out gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 3, 3, 1], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv1, pred1 = stochastic_depth_conv2d(inputs, 3, [3, 3], keep_prob, name='conv1')\n",
    "conv2, pred2 = stochastic_depth_conv2d(conv1, 3, [3, 3], keep_prob, name='conv2')\n",
    "conv3, pred3 = stochastic_depth_conv2d(conv2, 3, [3, 3], keep_prob, name='conv3')\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "var_list = tf.trainable_variables()\n",
    "grads = opt.compute_gradients(conv3, var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[1, 3, 3, 1]),\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    g, p1, p2, p3 = sess.run([grads, pred1, pred2, pred3], feed_dict)\n",
    "    print(p1, p2, p3)\n",
    "    for var, grad_value in zip(var_list, g):\n",
    "        grad, value = grad_value\n",
    "        print('',var.op.name, grad.squeeze(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Comparison\n",
    "\n",
    "Below, we can see that we only end up running a percentage of the convolutional layers, depending on whether it was dropped or not.\n",
    "\n",
    "Adjust the `keep_prob` parameter inside `feed_dict` in order to play around with different results. The expected runtime of the stocastic depth version of the network is approximately `keep_prob` times the length of the regular network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stochastic version\n",
    "tf.reset_default_graph()\n",
    "print('Building graph...')\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv, _ = stochastic_depth_conv2d(inputs, 32, [3, 3], keep_prob)\n",
    "for i in range(10):\n",
    "    conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "init = tf.global_variables_initializer()\n",
    "print('Done.')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[32, 228, 228, 3]),\n",
    "        # Adjust this parameter to see run speed adjust\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    print('Timing stochastic depth run...')\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard CNN version\n",
    "tf.reset_default_graph()\n",
    "print('Building graph...')\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "conv = tf.layers.conv2d(inputs, 32, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "for i in range(10):\n",
    "    conv = tf.layers.conv2d(conv, 32, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "init = tf.global_variables_initializer()\n",
    "print('Done.')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {inputs: np.random.normal(size=[32, 228, 228, 3])}\n",
    "    print('Timing standard run...')\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `while_loop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python `for` loop version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.1551680564880371 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "# Random inputs to multiply\n",
    "a = tf.random_normal([200, 200])\n",
    "b = tf.random_normal([200, 200])\n",
    "# Calculate value to add to accumulator variable\n",
    "mul = tf.matmul(a, b)\n",
    "mean = tf.reduce_mean(mul)\n",
    "acc = total.assign_add(mean)\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    for i in range(2000):\n",
    "        final_total = sess.run(acc)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `while_loop` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.11114311218261719 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "i = tf.constant(0)\n",
    "# Define the loop body\n",
    "def body(i, _):\n",
    "    a = tf.random_normal([200, 200])\n",
    "    b = tf.random_normal([200, 200])\n",
    "    mul = tf.matmul(a, b)\n",
    "    mean = tf.reduce_mean(mul)\n",
    "    acc = total.assign_add(mean)\n",
    "    return i+1, acc\n",
    "# Define the loop condition\n",
    "def condition(i, _):\n",
    "    return tf.less(i, 2000)\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(condition, body, [i, total])\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    final_i, final_total = sess.run(out)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensed version of the above\n",
    "\n",
    "This is the same graph from above, but condensed with by using a `lambda` and some TensorFlow sugar. We'll also export it so that we can explore it in `tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "# Define the loop body\n",
    "def body(i, _):\n",
    "    a = tf.random_normal([200, 200])\n",
    "    b = tf.random_normal([200, 200])\n",
    "    mul = tf.matmul(a, b)\n",
    "    mean = tf.reduce_mean(mul)\n",
    "    acc = total.assign_add(mean)\n",
    "    return i+1, acc\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(lambda i, _: i < 200, body, [0, total])\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "export_tensorboard_graph('while_loop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing with TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=tbout/while_loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What about \"unrolling\" the loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation time: 15.413125038146973 seconds\n",
      "Time elapsed: 8.42611312866211 seconds\n"
     ]
    }
   ],
   "source": [
    "# Unrolled version\n",
    "tf.reset_default_graph()\n",
    "graph_start_time = time.time()\n",
    "# Random inputs to multiply\n",
    "a = tf.random_normal([200, 200])\n",
    "for i in range(2000):\n",
    "    a = tf.matmul(a, tf.random_normal([200, 200]))\n",
    "graph_creation_time = time.time() - graph_start_time\n",
    "with tf.Session() as sess:\n",
    "    start_t = time.time()\n",
    "    final_total = sess.run(a)\n",
    "    end_t = time.time()\n",
    "    print('Graph creation time: {} seconds'.format(graph_creation_time))\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation time: 0.03203010559082031 seconds\n",
      "Time elapsed: 0.8657529354095459 seconds\n"
     ]
    }
   ],
   "source": [
    "# tf.while_loop version\n",
    "tf.reset_default_graph()\n",
    "graph_start_time = time.time()\n",
    "# Define the loop body\n",
    "def body(i, a):\n",
    "    with tf.name_scope('body'):\n",
    "        return i+1, tf.matmul(a, tf.random_normal([200, 200]))\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(lambda i, _: i < 2000, body, [0, tf.random_normal([200, 200])])\n",
    "graph_creation_time = time.time() - graph_start_time\n",
    "with tf.Session() as sess:\n",
    "    start_t = time.time()\n",
    "    final_i, final_total = sess.run(out)\n",
    "    end_t = time.time()\n",
    "    print('Graph creation time: {} seconds'.format(graph_creation_time))\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "\n",
    "`tf.dynamic_rnn` is implemented with a `tf.while_loop`. The actual implementation is much more robust (uses `RNNCell`, saves state at each step, accepts per-input lengths, etc), but this illustrates a basic example.\n",
    "\n",
    "If you want to save states from each time step, you'll want to use a `TensorArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf.while_loop version\n",
    "tf.reset_default_graph()\n",
    "x_input = tf.placeholder(tf.float32, [None, 20, 200])\n",
    "length_input = tf.placeholder(tf.int32, [])\n",
    "# Define the condition\n",
    "def cond(x, state, i, length):\n",
    "    return i < length\n",
    "# Define the loop body\n",
    "def body(x, state, i, length):\n",
    "    with tf.variable_scope('body', initializer=tf.random_normal_initializer()):\n",
    "        x_reshape = tf.reshape(x, [20, -1, 200])\n",
    "        # Get the input at timestep i\n",
    "        x_slice = tf.gather(x_reshape, i)\n",
    "        w = tf.get_variable('weight', [200, 200])\n",
    "        z = tf.matmul(x_slice + state, w)\n",
    "        a = tf.nn.tanh(z)\n",
    "        return x, a, i+1, length \n",
    "# Create the while_loop\n",
    "# Create zeros with dynamic shape based on inputs\n",
    "state_shape = tf.stack([tf.shape(x_input)[0], 200])\n",
    "start_state = tf.zeros(state_shape)\n",
    "# Create while_loop\n",
    "out = tf.while_loop(cond, body, (x_input, start_state, 0, length_input))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004956960678100586\n",
      "[[ 1.          0.89834851 -1.         ..., -0.99999952 -1.          1.        ]\n",
      " [-0.9999997   0.99973351  1.         ...,  1.         -0.27451974  1.        ]\n",
      " [-1.         -0.99999064  1.         ..., -0.99997503  1.          1.        ]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  1.         -1.          1.        ]\n",
      " [-1.         -1.         -0.99999958 ..., -1.          1.         -1.        ]\n",
      " [ 1.          1.         -1.         ..., -1.         -0.76782548\n",
      "   0.9072178 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        x_input: np.random.normal(size=[10, 20, 200]),\n",
    "        length_input: 20\n",
    "    }\n",
    "    start_t = time.time()\n",
    "    final_x, final_state, final_i, final_length = sess.run(out, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)\n",
    "    print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
